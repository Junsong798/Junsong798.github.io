<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>统计学 on Junsong Lu</title>
        <link>https://Junsong798.github.io/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/</link>
        <description>Recent content in 统计学 on Junsong Lu</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sun, 07 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://Junsong798.github.io/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>贝叶斯统计：Markov Chain Monte Carlo理论篇</title>
        <link>https://Junsong798.github.io/p/bayes-mcmc/</link>
        <pubDate>Sun, 07 May 2023 00:00:00 +0000</pubDate>
        
        <guid>https://Junsong798.github.io/p/bayes-mcmc/</guid>
        <description>&lt;img src="https://Junsong798.github.io/p/bayes-mcmc/fig1.png" alt="Featured image of post 贝叶斯统计：Markov Chain Monte Carlo理论篇" /&gt;&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;回顾2023年2-4月贝叶斯统计阅读路径，指明一些入门和进阶读物。接下来讨论为什么要用贝叶斯统计，并针对贝叶斯统计的难点Markov Chain Monte Carlo回顾所学。从最古老的Metropolis和Metropolis-Hastings开始，再基于高维空间的几何型态说明为什么经典算法对高维空间采样低效，再引入到更有效的Hamiltonian Monte Carlo以及其变体No-U-Turn Sampler。本文只讨论部分理论细节，不涉及应用，如empirical diagnosis，以及各种诊断识别性和加速收敛的方法。&lt;/p&gt;
&lt;h3 id=&#34;get-started&#34;&gt;Get Started&lt;/h3&gt;
&lt;p&gt;2022暑假阴差阳错听了几节Richard McElreath的&lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/Statistical-Rethinking-Bayesian-Examples-Chapman/dp/036713991X/ref=sr_1_1?crid=1XN66UYKAYUHB&amp;amp;keywords=statistical&amp;#43;rethinking&amp;amp;qid=1682993030&amp;amp;s=books&amp;amp;sprefix=statistical&amp;#43;rethin%2Cstripbooks%2C552&amp;amp;sr=1-1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Statistical Rethinking: A Bayesian Course with Examples in R and Stan&lt;/a&gt;，惊为天人。第一章对许多传统观点进行了挑战，“The Golem of Prague”将社会科学中常用的统计程序隐喻为巨大的陶土机器人，使用者稍有不甚便会引火烧身。其次，区分几种研究者常常混淆的概念——hypothesis，process model，statistical model。为什么检验理论困难？因为大多数时候，我们简略地把Null Hypothesis Significance Testing (NHST)理解为波普尔可证伪性原则，但是在实践中，任何单一假设（hypothesis）可能生成多个不同的过程模型（process model）。两个不同假设生成的两个不同的过程模型，可能被同一个统计模型（statistical model）支持。这说明支持与验证这个看似最根本的科学发现流程并不能帮助我们区分竞争性假设。更重要的一步是对假设进行重表述，在一组竞争性的过程模型中选择可以被统计模型区分的选项。后来参加工作，没时间听课，只学到grid approximation，rethinking课程就此搁置。&lt;/p&gt;
&lt;p&gt;2023年申请季所有面试结束后，开始读Kruschke的&lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/Doing-Bayesian-Data-Analysis-Tutorial/dp/0124058884/ref=sr_1_1?crid=2IA5P14C1TDTC&amp;amp;keywords=Doing&amp;#43;Bayesian&amp;#43;Data&amp;#43;Analysis%3A&amp;#43;A&amp;#43;Tutorial&amp;#43;with&amp;#43;R%2C&amp;#43;JAGS%2C&amp;#43;and&amp;#43;Stan&amp;#43;2nd&amp;#43;Edition&amp;amp;qid=1682993003&amp;amp;s=books&amp;amp;sprefix=bayesian&amp;#43;statistical&amp;#43;modeling&amp;#43;stan%2Cstripbooks%2C883&amp;amp;sr=1-1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan 2nd Edition&lt;/a&gt;。封面卖萌，暗示了本书定位是小朋友们的读物，不涉及太复杂的数学。作者在开头不厌其烦地为读者指明路径，对忙人和大忙人要读的章节悉数规划。最后读了：Ch2基础，Ch4概率论，Ch5贝叶斯公式，Ch6 binomial distribution，Ch7 Markov Chain Monte Carlo，Ch9 hierarchical models，Ch 10 model comparison，Ch 14 Stan。初学者难点在于理解MCMC的原理，Bayesian hierarchical model, 以及model comparison。这本书总体知识点比较老旧，数学证明少，模型比较部分缺乏近年的新进展，仅适用于基础。阅读期间的辅助材料，一些&lt;a class=&#34;link&#34; href=&#34;https://gregorygundersen.com/blog/2020/02/23/gibbs-sampling/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;blog提供的数学证明&lt;/a&gt;，以及Stanford计算机科学研究生课程&lt;a class=&#34;link&#34; href=&#34;https://cs.stanford.edu/~ermon/cs323/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CS 323: Automated Reasoning&lt;/a&gt;。主要看Metropolis-Hastings和Gibbs sampler相关的证明。&lt;/p&gt;
&lt;p&gt;在阅读MCMC的过程中，参考了Andrew Gelman的&lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/Bayesian-Analysis-Chapman-Statistical-Science/dp/1439840954&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bayesian Data Analysis 3rd&lt;/a&gt;。Gelman在MCMC部分讲得比较清晰，会把各种算法的步骤列出来。但是这本书很难，定位统计\计算机专业graduate level。但即便如此，Gelman也已经对复杂的MCMC，比如Hamiltonian Monte Carlo（HMC）进行了大量简化。严谨地理解HMC需要学习微分几何（differential geometry）。估计是得理论物理专业，了解广义相对论的人才有的背景。Gelman的书我还读了高斯过程模型（Gaussian Process Models），第一次学时感觉比较简略，看不明白，不如看论文和Stan manual清楚。一些Gelman的教材看不懂的地方，我又翻了&lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/Bayesian-Statistical-Methods-Springer-Statistics/dp/0387922997/ref=sr_1_1?crid=1EJC20EPWXRHU&amp;amp;keywords=a&amp;#43;first&amp;#43;course&amp;#43;bayesian&amp;amp;qid=1682990647&amp;amp;s=books&amp;amp;sprefix=a&amp;#43;first&amp;#43;course&amp;#43;bayesia%2Cstripbooks%2C563&amp;amp;sr=1-1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;A First Course in Bayesian Statistical Methods&lt;/a&gt;。证明过程比较详细。&lt;/p&gt;
&lt;p&gt;上手部分看的其他书。首先确定使用Stan概率编程语言。Stan的特点是社区好，开源，语法简单，基于C++和HMC的一个改良版No-U-Turn Sampler，采样速度快（相对于PyMC3等），模型设定非常flexible，有R和Python的调用接口。但是有一定学习门槛，要对模型背后统计比较清楚，不能无脑（其实brms包复杂一点的模型也不太能无脑）。入门时先听了几节大家强推的张磊老师的课程，&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=nwDSyTH3haM&amp;amp;list=PLfRTb2z8k2x8ZCqDJ0WEFNs2ymXQCliLa&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bayesian Statistics and Hierarchical Bayesian Modeling for Psychological Science&lt;/a&gt;。依葫芦画瓢把多层强化学习写了一遍。接下来花了一周多仔细读了一本基于Stan的贝叶斯教材&lt;a class=&#34;link&#34; href=&#34;https://vasishth.github.io/bayescogsci/book/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;An Introduction to Bayesian Data Analysis for Cognitive Science&lt;/a&gt;。特别是先验选择，prior predictive check，hierarchical model，Stan语法基础和抽样原理，posterior predictive check等技术。本书对model comparison的部分讲得特别好。具体来说，贝叶斯有两种视角进行模型比较，一类是基于先验的Bayes factor，另一类是基于后验的cross validation。做各种组间比较，比如ANOVA，以及确定样本量时，会用前者。后者是以预测的角度来评价模型，常见的指标有LOOIC。这种情况下像machine learning那样做cross validation往往算力不足，会用到一些近似方法来估计。之后还参考了&lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/Students-Guide-Bayesian-Statistics/dp/1473916364/ref=sr_1_1?crid=BK9XABKVWWFA&amp;amp;keywords=a&amp;#43;student&amp;#43;guide&amp;#43;bayesian&amp;amp;qid=1682991874&amp;amp;s=books&amp;amp;sprefix=a&amp;#43;student&amp;#43;guide&amp;#43;bayesi%2Cstripbooks%2C581&amp;amp;sr=1-1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;A Student’s Guide to Bayesian Statistics&lt;/a&gt;和&lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/Bayesian-Statistical-Modeling-Stan-Python/dp/9811947546/ref=sr_1_1?crid=37R4GCZQOSMG6&amp;amp;keywords=bayesian&amp;#43;statistical&amp;#43;modeling&amp;#43;stan&amp;amp;qid=1682991928&amp;amp;s=books&amp;amp;sprefix=bayesian&amp;#43;statistical&amp;#43;modeling&amp;#43;sta%2Cstripbooks%2C311&amp;amp;sr=1-1&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Bayesian Statistical Modeling with Stan, R, and Python&lt;/a&gt;。这两本书都对常见分布进行了总结，需要浏览，这样才知道怎么选似然函数和先验（e.g., 什么时候选student t，什么时候选Gaussian）。后者是一本非常accessible的应用教材，特别是讲了如何提高MCMC的收敛性，比如loosen posterior distribution by reparameterization（e.g., non-centered reparameterization降低参数的相关性），比如soft identification。还专门有一章讲解离散参数的估计。&lt;/p&gt;
&lt;p&gt;其他重要的资料，一些论文。必读&lt;a class=&#34;link&#34; href=&#34;https://link.springer.com/article/10.1007/s11222-016-9696-4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC&lt;/a&gt;。了解HMC，可以参考Michael Betancourt的&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1701.02434&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;A conceptual introduction to Hamiltonian Monte Carlo&lt;/a&gt;。Michael Betancourt的&lt;a class=&#34;link&#34; href=&#34;https://betanalpha.github.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;个人博客&lt;/a&gt;提供了质量很高的post，主要涉及概率理论和贝叶斯建模。了解MCMC diagnosis，看&lt;a class=&#34;link&#34; href=&#34;https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Stan官方文件&lt;/a&gt;和bayesplot R包。了解为什么对后验采样困难，需要理解高维空间的几何特性（hierarchical model动辄上千个参数）。对高维空间的特征，看统计学习圣经&lt;a class=&#34;link&#34; href=&#34;https://hastie.su.domains/ElemStatLearn/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Elements of Statistical Learning&lt;/a&gt;的第二章。&lt;/p&gt;
&lt;p&gt;从实践的角度出发，完全没有必要读太多理论性的东西。因为一些MCMC的假设，如geometric ergodicity很难在复杂模型上验证。而MCMC也只有少数的empirical diagnosis指标来推断模型可能的问题。实际中自己更常见的错误是prior选择不当（e.g., 缺少prior predictive check），参数化不合理导致部分参数空间曲率大，对模型背后的心理学理论理解不当导致参数范围设置错误，进而引发不可识别和弱不可识别的问题。修改这些东西并不涉及MCMC的细节，因为目前很多抽样算法可以自适应调整参数。&lt;/p&gt;
&lt;h3 id=&#34;bayes-or-not-bayes&#34;&gt;Bayes or not Bayes?&lt;/h3&gt;
&lt;p&gt;为什么要用贝叶斯？贝叶斯看起来多了很多不必要的东西，需要选择先验分布，需要多学一门概率编程语言，需要更多的算力，需要做prior/posterior predictive check，需要解决MCMC采样不收敛的问题。许多心理学方法学论文会告诉你贝叶斯的两类优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;对贝叶斯参数估计：对参数不确定性的估计（credible interval）比frequentism更符合人类认知，比最大似然估计（maximum likelihood estimation）更reliable，可以利用先验分布辅助不可识别的参数的估计（e.g., 用迪利克雷先验解决心理学常见的量表数据中部分categories零样本导致的回归不可识别问题）等等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对贝叶斯假设检验：本身没有对$H_0$的bias，可以评估虚无、备择假设的证据强度，可以不依赖sampling plan获取合适的样本量。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;工具塑造认知。做frequentist model非常方便，比如lme4一行代码可以估计linear mixed model，但实际上种种类似的程序让研究者被迫估计一些inflexible canned model，而这些model并不能很好地描述观测数据，这让修改模型、探索数据中新的模式成了少数人的路，阻碍了更多新的发现。此外，在假设检验中，当我们做frequentist models，我们习惯性把统计问题表述为一个统计量是否显著。相对于效应有多大，效应的不确定性有多大，这可能是一个&lt;a class=&#34;link&#34; href=&#34;https://compass.onlinelibrary.wiley.com/doi/full/10.1111/lnc3.12201?casa_token=H9p153a3WHYAAAAA%3AKaVlExrDuP0bOejO1zo3PrNw_FmPt__V3er-1PYL9nvcAj_0oL9hGc9l8gemUhwKZ4iJA5bUKa0plwGv&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;错误的问题&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;但是，以上讨论充其量是说明了贝叶斯相比频率学派有哪些优点，并不能完全说服我们使用贝叶斯。要了解为什么我们应该做贝叶斯，参考Betancourt的观点：在高维空间中，最优化无意义。&lt;/p&gt;
&lt;p&gt;比较两种参数估计的思路，一种是非常常用的maximum a posteriori (MAP) estimate:&lt;/p&gt;
&lt;p&gt;$$\theta^* = argmax\ \pi(\theta|y) = argmax\ \pi(y|\theta)\pi(\theta)$$&lt;/p&gt;
&lt;p&gt;当使用non-informative prior时，等价为Maximum likelihood estimation (MLE)：&lt;/p&gt;
&lt;p&gt;$$\theta^* = argmax\ \pi(y|\theta)$$&lt;/p&gt;
&lt;p&gt;另一种是贝叶斯统计中常见的求解期望：&lt;/p&gt;
&lt;p&gt;$$E(\theta^*) = \int d\theta \pi(\theta)\theta$$&lt;/p&gt;
&lt;p&gt;这两种方法的根本不同在于，MAP在参数估计时用的是概率密度（probability density），而后者用的是概率质量（probability mass）。有意思的地方在于，概率密度并不是一个fundamental object，而是会随着不同的参数化改变的值：&lt;/p&gt;
&lt;p&gt;$$d\pi(\theta) = d\theta\pi(\theta)$$&lt;/p&gt;
&lt;p&gt;严格意义上的理解需要测度论的知识。但可以从不太精确，但是intuitive的方式来理解。见下文typical set部分——将二维实数集用立体投影映射到一个球体中的例子。&lt;/p&gt;
&lt;p&gt;这里想要表达的意思是，一种参数化其实是一个特定的在不同空间之间映射的过程。如果我们的模型估计是正确的，那么我们的估计就不应该受到特定参数化的影响。从这个角度来说，MAP是错误的，因为它是利用一个‘变量’来估计参数。&lt;/p&gt;
&lt;h3 id=&#34;bayes-rule-and-markov-chain-monte-carlo&#34;&gt;Bayes&amp;rsquo; Rule and Markov Chain Monte Carlo&lt;/h3&gt;
&lt;p&gt;贝叶斯参数估计的主要难点在于估计贝叶斯公式的计算。回顾贝叶斯公式：&lt;/p&gt;
&lt;p&gt;$$p(\theta|y) = \frac{p(\theta)p(y|\theta)}{p(y)}$$
$$p(y) = \int_{\Theta}p(\theta)p(y|\theta)d\theta$$&lt;/p&gt;
&lt;p&gt;其中y为数据，$\theta$为参数，分母p(y)称为marginal likelihood。贝叶斯公式的直观理解是，给定了数据和当前的先验分布（没有数据时的分布），参数的分布应该是怎样的。拿我校入学疫苗政策举例，我们在测肺结核的时候，由于中国学生小时候接种过BCG卡介苗，皮试会有一定概率假阳，所以需要额外测X光。这是因为，先验分布对后验分布影响很大，如果数据只有一次（肺结核检测出阳性，判断是否有病），一乘上先验分布（人口中有肺结核的比率），即使sensitivity很高，乘积依然可能很小，基本都是没病的假阳。所以解决方法是增加数据，让likelihood的影响更大。&lt;/p&gt;
&lt;p&gt;p(y)的计算是贝叶斯参数估计的主要障碍，因为对一组连续变量，往往需要重积分，难以计算解析解。之所以需要计算分母，是因为prior与likelihood的乘积不是概率分布，需要一个normalizer。而之所以需要转换为概率分布，是因为unnormalized posterior density无法提供参数的不确定性信息——无法计算credible interval, 甚至连均值都无法求解。唯一获得的只有mode这一个信息。因此，求解unnormalized posterior density的mode也等价于频率学派的maximum likelihood estimation。&lt;/p&gt;
&lt;p&gt;历史上，对后验分布的估计往往采用conjugate prior，特定的likelihood function与特定的prior相乘，产生一个可以求解的积分。比如，Bernoulli likelihood function配合Beta prior，使得后验分布依然为Beta。但此方法对likelihood function有较多限制，逐渐被抛弃。另一种历史方法是数值近似方法，比如grid approximation，但是计算复杂度随着参数增加呈指数增长，只作为toy model教学使用。目前更多使用变分贝叶斯（variational Bayes）和Markov Chain Monte Carlo方法。&lt;/p&gt;
&lt;p&gt;第一次接触变分贝叶斯是在neuromatch academy的deep learning课程，generative model的课上，主要了解variational autoencoder是如何估计后验分布的。变分推断主要是一种最优化方法（听起来就很不Bayes），寻找一个分布和目标分布的差异，比如KL divergence最小，即可估计出后验分布。另一种现代方法是基于unnormalized posterior density进行采样，通过抽样样本对后验进行近似，即Markov Chain Monte Carlo方法。&lt;/p&gt;
&lt;p&gt;变分推断的优点在于计算快，并且其过程是决定性的。而MCMC的过程计算量大，带有随机性，可能受到初始值影响。而MCMC的优点在于其是asymptotically exact的，当采样足够长的时间步数，可以得到准确的后验分布估计，此外该方法所需假设少（仅需要能计算非标化后验），面对复杂的模型也一样有效，比如multimodal, hierarchical model.&lt;/p&gt;
&lt;h3 id=&#34;the-metropolis-algorithm-and-the-metropolis-hastings-algorithm&#34;&gt;The Metropolis Algorithm and the Metropolis-Hastings Algorithm&lt;/h3&gt;
&lt;p&gt;下面从最简单的Metropolis algorithm来看MCMC方法的工作原理。所谓metropolis algorithm，就是通过一个点（采样器）在样本空间随机游走，并记录走过的位置的抽样方法。通过不断抽样，再对抽出的样本进行统计，近似后验分布。首先明确几个概念。第一个是proposal distribution（$J$），指的是样本移动方案的分布，其规定了向各个参数空间移动的概率分布。第二个是target distribution（$\pi$），指的是需要还原的后验分布。&lt;/p&gt;
&lt;p&gt;Metropolis algorithm表述如下：&lt;/p&gt;
&lt;p&gt;给定一个参数初始值，在t = 1, 2, &amp;hellip;n时间步内，基于proposal distribution抽样一个新的proposal，即下一步可能移动到的position $\theta^{*}$，然后基于下式计算一个概率比值:&lt;/p&gt;
&lt;p&gt;$$r = \frac{p(\theta^{\ast}|y)}{p(\theta^{t-1}|y)}$$&lt;/p&gt;
&lt;p&gt;注意本式中没有出现proposal distribution，因为算法存在一个假定，即目标分布对称：&lt;/p&gt;
&lt;p&gt;$$J_t(\theta_a|\theta_b) \equiv J_t(\theta_b|\theta_a)$$&lt;/p&gt;
&lt;p&gt;当目标分布对称时，任意两个点a,b之间向对方位置提出proposal的概率相等。此时t时刻$\theta$的分布为：&lt;/p&gt;
&lt;p&gt;$$\theta^{t}=\begin{cases} \theta^{\ast} \ \ \ \  min(r, 1) \\ \theta^{t-1} \ \ \ 1-min(r,1).\end{cases}$$&lt;/p&gt;
&lt;p&gt;如果proposal被接受，则移动到下一个点，否则停留在当前位置，并算作一次采样。其中，我们定义acceptance distribution为：&lt;/p&gt;
&lt;p&gt;$$A(\theta^{\ast}|\theta^{t-1})= min(r,1)$$&lt;/p&gt;
&lt;p&gt;一个案例是，一个politician要根据7个岛的人口确定造访各个岛屿的频率，但是他有觉得制定计划过于麻烦，所以采取了一个启发式。启发式如下：&lt;/p&gt;
&lt;p&gt;当处于某个岛屿θ时，抛硬币决定去左边θ-1还是右边的岛θ+1，根据min{p(θ-1)/p(θ), 1}或min{p(θ+1)/p(θ), 1}决定去留。如果proposed position的相对人口P比当前位置的P更大，则必定移动。p这里指的是相对人口，而在启发式中也仅仅是需要两个p的比值。&lt;/p&gt;
&lt;p&gt;也就是说当我们的target distribution是一个后验分布p(θ)时，他与p(D|θ)p(θ)成比率。可见MCMC的好处就是不需要知道p(D)，也能进行抽样。而且抽出的样本符合后验分布。&lt;/p&gt;
&lt;p&gt;要理解为什么MCMC有效，需要说明transition probabilities（P，从参数空间某一点移动到另一点）的比值等于target distribution的比值。以上述Metropolis algorithm为例：&lt;/p&gt;
&lt;p&gt;$$\frac{P(\theta_a \rightarrow \theta_b)}{P(\theta_b \rightarrow \theta_a)}=\frac{J_t(\theta_b|\theta_a)*min(\pi(\theta_b)/\pi(\theta_a),1)}{J_t(\theta_a|\theta_b)*min(\pi(\theta_a)/\pi(\theta_b),1)} = \frac{\pi(\theta_b)}{\pi(\theta_a)}$$&lt;/p&gt;
&lt;p&gt;注意transition probability是proposal和acceptance probability的乘积。因为transit到一个状态，首先必须propose到该状态，其次还要accept该状态。由于J是一个symmetric proposal distribution，相互抵消。而我们仅需要目标分布的比值，所以我们也可以用非标化后验概率的比值（p）来计算。总结，我们会根据后验概率密度在参数空间中采样，各个点上的采样数和后验概率密度成比例，所以我们能还原后验分布。&lt;/p&gt;
&lt;p&gt;实际中，Metropolis对proposal distribution对称性的要求会降低采样效率。这是因为它只能在某一点领域内提出proposal，自相关强（有效样本量低），而且移动到概率密度高的区域需要大量时间步。因此可以放宽这个假定。Metropolis-Hastings algorithm是Metropolis algorithm的特殊形式，即不需要满足：&lt;/p&gt;
&lt;p&gt;$$J_t(\theta_a|\theta_b) \equiv J_t(\theta_b|\theta_a)$$&lt;/p&gt;
&lt;p&gt;但为了保证访问各个参数空间的频率是等比于target distribution的，就需要对这个不对称性进行矫正，用非标化后验除以propose到某个参数空间的概率，这样使得最后的比率仍然反应了后验概率的比例：&lt;/p&gt;
&lt;p&gt;$$r = \frac{p(\theta^{\ast}|y)/J_t(\theta^{\ast}|\theta^{t-1})}{p(\theta^{t-1}|y)/J_t(\theta^{t-1}|\theta^{\ast})}$$&lt;/p&gt;
&lt;p&gt;则：&lt;/p&gt;
&lt;p&gt;$$\theta^{t}=\begin{cases} \theta^{\ast} \ \ \ \ min(r, 1) \ \theta^{t-1} \ \ \ 1-min(r,1).\end{cases}$$&lt;/p&gt;
&lt;p&gt;下面说明为什么Metropolis-Hastings算法有效。&lt;/p&gt;
&lt;p&gt;总体证明思路是，在MCMC中，达成细致平衡（detailed balance）的分布是平稳分布（stationary distribution），而满足某些条件的马尔可夫链有唯一平稳分布，所以只需要证明目标分布（target distribution）能达成细致平衡即可。&lt;/p&gt;
&lt;p&gt;先看细致平衡的条件：&lt;/p&gt;
&lt;p&gt;$$\forall a,b, P(\theta_a \rightarrow \theta_b)\pi_a = P(\theta_b \rightarrow \theta_a)\pi_b$$&lt;/p&gt;
&lt;p&gt;这个式子有一个直观的解释，就是当达成分布$\pi$时，任意两点之间没有净流量或者净概率密度流动，使得MCMC继续采样仍然维持当前分布，所以叫balance，stationary。以上两种算法其实全是基于细致平衡这一条件来构造。对上式变形：&lt;/p&gt;
&lt;p&gt;$$\frac{P(\theta_a \rightarrow \theta_b)}{P(\theta_b \rightarrow \theta_a)} = \frac{\pi(\theta_b)}{\pi(\theta_a)}$$&lt;/p&gt;
&lt;p&gt;就是我们上面说明的Metropolis的工作原理。更具体的，当proposal distribution不对称时：&lt;/p&gt;
&lt;p&gt;$$\frac{P(\theta_a \rightarrow \theta_b)}{P(\theta_b \rightarrow \theta_a)} = \frac{J_t(\theta_b|\theta_a)A(\theta_b|\theta_a)}{J_t(\theta_a|\theta_b)A(\theta_a|\theta_b)} = \frac{\pi(\theta_b)}{\pi(\theta_a)}$$&lt;/p&gt;
&lt;p&gt;$$\frac{A(\theta_b|\theta_a)}{A(\theta_a|\theta_b)} = \frac{\pi(\theta_b)J_t(\theta_a|\theta_b)}{\pi(\theta_a)J_t(\theta_b|\theta_a)}$$&lt;/p&gt;
&lt;p&gt;可以通过构造A：&lt;/p&gt;
&lt;p&gt;$$A(\theta_b|\theta_a)= min(r,1)$$&lt;/p&gt;
&lt;p&gt;使得上述式子，即细致平衡成立。下面给出具体证明，说明Metropolis-Hastings是有效的。&lt;/p&gt;
&lt;p&gt;首先明确定理Ergodic Theorem: 一个不可约的（irreducible），非周期性的（aperiodic），常返的（recurrent）马尔科夫链存在唯一的平稳分布。简单总结，不可约指的是在任何一个状态作为初始点，在后续的某个时刻都能抵达其他的所有状态或参数空间。一个不满足不可约性的马尔可夫链是令X等于非零整数，$J_s$随机给X加减2，这使得如果X的初始值是奇数，永远不可能得到偶数。实际抽样当然不希望存在这种特性。周期性指的是每k个循环才能访问某个状态，非周期性则没有此限制。一个值x常返说的是在有限时间内总能再次取回这个值。一般情况下，以常规proposal distribution $J$，比如normal，比如uniform构造的马尔科夫链常常能满足上述三个性质，从而具有唯一平稳分布。&lt;/p&gt;
&lt;p&gt;当马尔科夫链存在唯一平稳分布后，只需要证明目标分布是平稳分布即可。这里涉及的概念是可逆性（reversible）。可逆性定义为，如果一个马尔科夫链存在一个满足细致平衡的分布$\pi^*$，则认为该马尔科夫链是可逆的：&lt;/p&gt;
&lt;p&gt;$$\forall i,j, \ \pi^{\ast}_i\ P(\theta_i \rightarrow \theta_j)=\pi^{\ast}_j\ P(\theta_j \rightarrow \theta_i)$$&lt;/p&gt;
&lt;p&gt;结合定理：如果一个分布$\pi^*$是可逆的，则该分布是一个平稳分布。&lt;/p&gt;
&lt;p&gt;接下来证明，target distribution $p$是可逆的，满足细致平衡：&lt;/p&gt;
&lt;p&gt;假设在target distribution中，$p(\theta_j|y)≥p(\theta_i|y)$，则t-1时刻位处i，t时刻位于j的概率为：&lt;/p&gt;
&lt;p&gt;$$p(\theta^{t-1}=\theta_i, \theta^{t}=\theta_j)=P(\theta_i \rightarrow \theta_j)=p(\theta_i|y)J(\theta_j|\theta_i)$$&lt;/p&gt;
&lt;p&gt;根据我们的假设，此时$r$等于1. 其次，看t时刻位处i，t-1时刻位于j的概率：&lt;/p&gt;
&lt;p&gt;$$p(\theta^{t}=\theta_i, \theta^{t-1}=\theta_j)=p(\theta_j|y)J(\theta_i|\theta_j)\frac{p(\theta_i|y)J_t(\theta_j|\theta_i)}{p(\theta_j|y)J_t(\theta_i|\theta_j)}$$&lt;/p&gt;
&lt;p&gt;结合上述两式，得到：&lt;/p&gt;
&lt;p&gt;$$p(\theta^{t-1}=\theta_i, \theta^{t}=\theta_j)=p(\theta^{t}=\theta_i, \theta^{t-1}=\theta_j)$$&lt;/p&gt;
&lt;p&gt;发现$\theta^{t-1}, \theta^{t}$的联合分布是对称的，满足细致平衡，说明目标分布为平稳分布。而上述马尔科夫链又有唯一平稳分布，所以目标分布是该马尔科夫链的平稳分布。该马尔可夫链在模拟一定时间后收敛于目标分布。&lt;/p&gt;
&lt;p&gt;更直观的，利用上述联合分布对称的性质，求解t时刻的边缘分布：&lt;/p&gt;
&lt;p&gt;$$p(\theta^t=\theta)=\int p(\theta^t=\theta, \theta^{t-1}=\theta_i)d\theta_i=\int p(\theta^t=\theta_i, \theta^{t-1}=\theta)d\theta_i=p(\theta^{t-1}=\theta)$$&lt;/p&gt;
&lt;p&gt;所以，如果t-1时刻是目标分布，t时刻仍然保持了目标分布。&lt;/p&gt;
&lt;p&gt;总结，所谓的证明就是从设计的反面说明目标分布能达成细致平衡。&lt;/p&gt;
&lt;h3 id=&#34;gibbs-sampling&#34;&gt;Gibbs Sampling&lt;/h3&gt;
&lt;p&gt;另一种Metropolis-Hastings Algorithm的特例是Gibbs sampling，将proposal distribution设置为一个条件分布，从而使得acceptance probability恒为1，提高采样速度。Gibbs sampling的proposal distribution如下：&lt;/p&gt;
&lt;p&gt;$$J(\theta^{\ast}|\theta^{t-1})=\begin{cases} p({\theta^{\ast}&lt;em&gt;{j}}|{\theta^{t-1}&lt;/em&gt;{-j}}, y) \ \ \ \ min(r, 1) \ 0 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 1-min(r,1) \end{cases}$$&lt;/p&gt;
&lt;p&gt;$$
J(\theta^{\ast}|\theta^{t-1}) = \begin{cases}
p(\text{$\theta^{\ast}&lt;em&gt;{j}$}|\text{$\theta^{t-1}&lt;/em&gt;{-j}$}, y) &amp;amp; \text{ } \min(r, 1) \
0 &amp;amp; \text{ } 1 - \min(r, 1)
\end{cases}
$$&lt;/p&gt;
&lt;p&gt;$$J(\theta^{\ast}|\theta^{t-1})=\begin{cases} p({\theta^{\ast}_{j}}|{\theta^{t-1}_{-j}}, y) \ \ \ \ min(r, 1) \ 0 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 1-min(r,1) \end{cases}$$&lt;/p&gt;
&lt;p&gt;采样开始时，给定参数空间初始值，对每一个时间步，随机或者按顺序抽取一个参数$\theta_j$，计算给定数据y和其他参数$\theta_{-j}$时的条件概率并对其采样，得到新的proposal。这说明Gibbs sampling每次只更新一个参数。计算：&lt;/p&gt;
&lt;p&gt;$$r = \frac{p(\theta^{\ast}|y)/J_t(\theta^{\ast}|\theta^{t-1})}{p(\theta^{t-1}|y)/J_t(\theta^{t-1}|\theta^{\ast})} \= \frac{p(\theta^{\ast}|y)/p(\theta^{\ast}&lt;em&gt;{j}|\theta^{t-1}&lt;/em&gt;{-j}, y)}{p(\theta^{t-1}|y)/p(\theta^{t-1}&lt;em&gt;{j}|\theta^{t-1}&lt;/em&gt;{-j}, y)}$$&lt;/p&gt;
&lt;p&gt;又有：&lt;/p&gt;
&lt;p&gt;$$\theta^{\ast} = (\theta^{\ast}&lt;em&gt;j, \theta^{t-1}&lt;/em&gt;{-j}) \ \theta^{t-1} = (\theta^{t-1}&lt;em&gt;j, \theta^{t-1}&lt;/em&gt;{-j})$$&lt;/p&gt;
&lt;p&gt;则：&lt;/p&gt;
&lt;p&gt;$$r = \frac{p(\theta^{\ast}&lt;em&gt;j | \theta^{t-1}&lt;/em&gt;{-j},y)/p(\theta^{\ast}&lt;em&gt;{j}|\theta^{t-1}&lt;/em&gt;{-j}, y)}{p(\theta^{t-1}&lt;em&gt;j | \theta^{t-1}&lt;/em&gt;{-j},y)/p(\theta^{t-1}&lt;em&gt;{j}|\theta^{t-1}&lt;/em&gt;{-j}, y)} \ = 1$$&lt;/p&gt;
&lt;h3 id=&#34;hamiltonian-monte-carlo-hmc&#34;&gt;Hamiltonian Monte Carlo (HMC)&lt;/h3&gt;
&lt;p&gt;尝试从设计的角度来理解HMC，先介绍高维空间的几何特性。这种特性引出了一个概念，typical set，决定了sampler在空间中需要游走的位置。为了满足这种游走规则，利用Hamiltonian来制约MCMC的轨迹。最后讨论这种物理过程背后涉及一系列参数和对抽样的影响。&lt;/p&gt;
&lt;h4 id=&#34;typical-set&#34;&gt;Typical Set&lt;/h4&gt;
&lt;p&gt;HMC的诞生是基于经典算法，如Metropolis-Hastings和Gibbs sampler在高维参数空间中采样过于低效，而且难以在有限时间内收敛的现状。首先要通过理解高维空间中后验分布的形状来理解为什么高维空间采样困难。给定一个D-dimensional标准正态分布，其形状类似一个很细的圆环，或者甜甜圈一样的形状。如果是一个固定不变的，或者对称的proposal distribution，很难有效探索大部分参数空间，因为后验太细，大部分proposal被拒绝。或者是一次只改变少数参数的proposal，可能会直接跳过这个狭窄区域。对贝叶斯估计来说，我们的最终目的是估计参数空间Q中样本q（理解为参数可采样的值）的期望（e.g., 可以是后验的mean或variance，本质都是期望）：&lt;/p&gt;
&lt;p&gt;$$E[f] = \int_{Q} dq \pi(q)f(q)$$&lt;/p&gt;
&lt;p&gt;精准估计上述公式，MCMC采样需要能还原有代表性的后验分布区域，因此这里引入一个重要概念，叫typical set。原始概念出自information theory，但在Stan的语境下，这个概念的含义有所不同。从一个宽泛的角度来说，typical set指的是后验分布mode周围的一片区域，这些区域比较宽而且有较高的probability density ($\pi(q)$)，所以对期望的贡献大。Betancourt给了另一种界定（有争议，比如Andrew Gelman就不同意这种说法）。在上述公式中，dq这个微分常量被称为“volume”。在一元积分中，dq就是一段无穷小距离。二元积分则是一个小平面$d\sigma$：&lt;/p&gt;
&lt;p&gt;$$\int_{D} f(x,y) d\sigma$$&lt;/p&gt;
&lt;p&gt;拓展到高维，就是一个高维空间（体积）。在我们通常认知里，比如二维情况下的黎曼积分，无论距离空间中任意一点多远，这个无穷小量都是定值。Betancourt却说，这个假设在高维空间中不成立了。假设以后验分布的mode为原点，距离mode越远的地方，这个高维体积volume就会越大，并且以指数增加，趋近无穷。另一方面，离mode越远，对应参数空间的概率密度越小，逐渐趋近于0。反观期望公式dq和$\pi(q)$的乘积决定了对应点对期望的影响大小。所以保证在该乘积最大的位置采样，规避该乘积较小的位置，可以在节省算力的情况下对期望有最准确的估计。&lt;/p&gt;
&lt;p&gt;想要理解为什么volume不是常量是非常困难的。其实Betancourt并不是说volume不是常量，他认为在空间中任意点的邻域，这个volume都是定值。他所要强调的是，&lt;a class=&#34;link&#34; href=&#34;https://stats.stackexchange.com/questions/321260/understanding-the-typical-set-for-markov-chain-monte-carlo-sampling&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;距离任一点，增加同样的几何距离时，样本空间中的点都会更加密集&lt;/a&gt;。这导致这些区域对期望的贡献会很大。在&lt;a class=&#34;link&#34; href=&#34;https://betanalpha.github.io/assets/case_studies/probabilistic_computation.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;博客&lt;/a&gt;中，他给了两个例子:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;对一个D-dimensional sphere，在距离圆心O外一点x，和一个微小常量$\delta$，x-$\delta$和x+$\delta$这两个距离上的体积差异，会随着维度增加而增加。这意味着在参数空间中，远离mode的区域会有囊括更多的样本点。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选定一个二维实数集上的一点O，对整个二维实数集进行立体投影，得到一个包含了O的球体。这个球体远离O的地方会囊括更多的实数，直到球体另一端的一个点包含了无穷多的实数。为啥，因为实数集是一个无穷的平面，如果要选定一个点O然后投射到一个有限球体中，距离O很远的无穷个点会被强行挤压进离O较远的空间中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一句题外话，个人感觉这两个例子不如ESL第二章curse of dimensionality和&lt;a class=&#34;link&#34; href=&#34;https://yuhangzhou88.github.io/ESL_Solution/ESL-Solution/2-Overview-of-Supervised-Learning/ex2-3/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Exercise 2.3的证明&lt;/a&gt;来得直观。从ESL的例子来理解就是，当维数很高的时候，在任意一点周围一个极小的volume进行采样，也需要涵盖各个维度上比较大的一个range，根本不是所谓的‘邻域’。假设数据点在高维空间均匀分布的情况下，大部分都跑到邻域外去了。在MCMC的语境下的一个implication就是，如果采样器基于简单的非标化后验，那么由于数据的稀疏，大部分proposal会被拒绝。&lt;/p&gt;
&lt;h4 id=&#34;earths-moon&#34;&gt;Earth&amp;rsquo;s Moon&lt;/h4&gt;
&lt;p&gt;即使远处的空间会趋近于无穷大，但是由于远离后验分布的mode，其概率密度很低。这里看出，一个好的MCMC采样方法是在两种策略之间权衡：要保证随机游走尽可能靠近后验分布mode的位置，但是又不能太靠近导致对mode周围大量高密度区域缺少探索。&lt;/p&gt;
&lt;p&gt;前面说过，经典算法面对收窄的高维空间，很容易跳过后验密度高的区域。那么一个很自然的想法就是构建一个vector field，让采样器沿着typical set的向量场绕圈，而不是在进入typical set以后仍然随机提出proposal，又跑到其他空间采样。&lt;/p&gt;
&lt;p&gt;上述统计过程可以用一个重力场来类比。Betancourt说，任何一个概率系统，都有一个数学上等价的物理系统。考虑一个绕地球的卫星。其受到地球重力影响，如果卫星速度为0，就会冲向地球坠毁。如果卫星速度过大，大于第二宇宙速度，会脱离地球飞向太阳系。而介于第一、第二宇宙速度之间时，可以绕地球公转。这个物理系统是能量守恒的，这保证了卫星在既定轨道上运行。在这里，绕地球公转的轨迹就是typical set（高维的甜甜圈），重力场是后验分布的梯度（gradient），而卫星的速度就是接下来HMC要引入的momentum参数。能量守恒则对应Hamiltonian的守恒，这保证采样器在typical set上采样。&lt;/p&gt;
&lt;h4 id=&#34;hamiltons-equations&#34;&gt;Hamilton’s Equations&lt;/h4&gt;
&lt;p&gt;对HMC一般性的理解，可以如下概括。对非标化后验取负对数，形成一个山谷的形状。将MCMC采样器理解为一个小球，随机放置于山谷的一个位置，并抽取一个初始的动量让其滚动，这个滚动中包含了一系列由自适应算法控制的离散步骤，然后一定步数后停止，获得下一个propose的位置，根据transition probability的公式计算是否accept。&lt;/p&gt;
&lt;p&gt;首先假设模型有D个参数，那么添加D个动量参数$p_n$，将D-dimensional parameter space拓展到2D，这个空间称为相空间（phase space）：&lt;/p&gt;
&lt;p&gt;$$q_n \rightarrow (q_n, p_n)$$&lt;/p&gt;
&lt;p&gt;则目标分布变为：&lt;/p&gt;
&lt;p&gt;$$\pi(q,p) = \pi(p|q) \pi(q)$$&lt;/p&gt;
&lt;p&gt;因为我们并不关心momentum的分布，这样参数化后可以将p参数marginalize out，就得到了之前的D维后验分布。题外说一句，贝叶斯中的reparameterization并不改变后验分布的期望，所以无论怎么参数化，理论上不对最后结果产生影响。这是因为本质上用MCMC采样是在估计一个joint posterior distribution。参数化改变的是变量之间的依赖关系，从而影响局部变量之间的边缘后验分布的形状，导致了不同参数化之间抽样效率的差异。比如hierarchical model就是一种基于数据的假设确定的参数化方法，一来是便于理解模型，二是由于参数的依赖性，同样一部分数据可以同时inform多个参数。在物理上，当系统能量守恒时，重参数化相当于改变了volume的形状，空间在一个维度上受到挤压则在另一个维度上延展。&lt;/p&gt;
&lt;p&gt;由于后验分布不变，现定义一个相应的常量，Hamiltonian function:&lt;/p&gt;
&lt;p&gt;$$H(q,p) \equiv -log \pi(q,p)$$&lt;/p&gt;
&lt;p&gt;$$H(q,p) \equiv -log \pi(q|p) -log\pi(q)$$&lt;/p&gt;
&lt;p&gt;$$H(q,p) \equiv K(p,q) + U(q)$$&lt;/p&gt;
&lt;p&gt;可以理解为系统的动能K和势能U守恒。其中势能仅仅和我们的目标分布有关，而动能需要额外定义。在实践中，一般以一个二次型来表示，使其服从多元高斯分布：&lt;/p&gt;
&lt;p&gt;$$p \sim N_q(0, \bold{M})$$&lt;/p&gt;
&lt;p&gt;其中M是正定矩阵。Hamiltonian function变为：&lt;/p&gt;
&lt;p&gt;$$H(q,p) \equiv \frac{1}{2}p^TM^{-1}p -log\pi(q)$$&lt;/p&gt;
&lt;p&gt;这个Hamiltonian表示了动能和势能的权衡，从而刻画了参数空间中的typical set。当势能大时，会转化为动能拉回mode，而当动能大时，又使得sampler逃离mode。HMC本身就是以此在相空间中进行Hamiltonian dynamics的演化。更进一步，用Hamilton&amp;rsquo; equations来刻画q和p随着时间的变化：&lt;/p&gt;
&lt;p&gt;$$\frac{dp}{dt} = -\frac{\partial H(q,p)}{\partial q} = -\frac{\partial K(q,p)}{\partial q} - \frac{\partial U(q)}{\partial q}$$&lt;/p&gt;
&lt;p&gt;$$\frac{dq}{dt} = \frac{\partial H(q,p)}{\partial p} = \frac{\partial K(q,p)}{\partial p}$$&lt;/p&gt;
&lt;p&gt;考虑到一般认为momentum（p）独立于参数q，上述式子可简化为：&lt;/p&gt;
&lt;p&gt;$$\frac{dp}{dt} = - \frac{\partial U(q)}{\partial q} = \bigtriangledown_{q}log\pi(q)$$&lt;/p&gt;
&lt;p&gt;$$\frac{dq}{dt} = \frac{\partial K(q,p)}{\partial p} = \bold{M}^{-1}p$$&lt;/p&gt;
&lt;p&gt;其中$\bigtriangledown_{q}log\pi(q)$为目标函数的梯度。Hamilton&amp;rsquo; equations的解是一个刻画了q和p随时间演化的函数。这为后续确定proposed position确定了条件。&lt;/p&gt;
&lt;h4 id=&#34;the-three-steps-of-an-hmc-iteration&#34;&gt;The Three Steps of an HMC Iteration&lt;/h4&gt;
&lt;p&gt;迭代开始时，先基于动量矩阵进行采样，获得一个动量（step 1），然后进行Hamiltonian dynamics模拟（step 2），基于模拟结果提出下一个iteration的proposal。最后计算是否接受proposal（step 3）。&lt;/p&gt;
&lt;p&gt;实际应用中，在相空间中模拟Hamiltonian dynamics连续过程存在困难，所以一般会用一系列离散的时间步来模拟。即一段时间内q和p的轨迹被切分成一系列离散的step（epsilon）。设这个step的数量为L，则一次HMC迭代（iteration）中间经过了step*L时长的Hamiltonian dynamics。&lt;/p&gt;
&lt;p&gt;更具体的，p和q的更新方法叫做leapfrog method:&lt;/p&gt;
&lt;p&gt;$$p(t+\frac{\epsilon}{2}) = p(t) + \frac{\epsilon}{2}\bigtriangledown_{q}log\pi(q(t))$$&lt;/p&gt;
&lt;p&gt;$$q(t+\epsilon) = q(t) + \epsilon\bold{M}^{-1}p(t+\frac{\epsilon}{2})$$&lt;/p&gt;
&lt;p&gt;$$p(t+\epsilon) = p(t+\frac{\epsilon}{2}) + \frac{\epsilon}{2}\bigtriangledown_{q}log\pi(q(t+\epsilon))$$&lt;/p&gt;
&lt;p&gt;以上步骤重复L次，则得到更新后的q和p在相空间的位置，q*，p*。又令总时间为：&lt;/p&gt;
&lt;p&gt;$$T = \epsilon * L$$&lt;/p&gt;
&lt;p&gt;便可以用类似Metropolis-Hastings的transition probability来计算接受本次迭代proposal的概率：&lt;/p&gt;
&lt;p&gt;$$r = \frac{\pi(q^{\ast},p^{\ast})}{\pi(q^{T-1},p^{T-1})} \ = \frac{exp(-H(q^{\ast},p^{\ast}))}{exp(-H(q^{T-1},p^{T-1}))}$$&lt;/p&gt;
&lt;p&gt;$$q^T=\begin{cases} q^{\ast} \ \ \ \ min(r, 1) \ q^{T-1} \ \ \ 1-min(r,1).\end{cases}$$&lt;/p&gt;
&lt;p&gt;公式也基于细致平衡推导。由于能量守恒，理论上r总是接近于1，所以proposal必然accept。但由于leapfrog是一种近似，所以r并不总是等于1，这相当于对leapfrog integrator误差的校正。&lt;/p&gt;
&lt;h4 id=&#34;hmc-algorithm-parameters-and-no-u-turn-sampler&#34;&gt;HMC algorithm parameters and No-U-Turn Sampler&lt;/h4&gt;
&lt;p&gt;综上可见，HMC的主要参数有step size ($\epsilon$)，L，和协方差矩阵$\bold{M}$。对这些参数的设置会影响抽样效率和收敛性。&lt;/p&gt;
&lt;p&gt;对$\epsilon$，如果过大，会使得数值积分不精确，即对Hamilton&amp;rsquo; equations的解不准，导致能量不守恒。如果能量与预设值相差过大，则并不能保证在typical set中采样。很好理解，比如用多个细长的矩形去估计一个平滑曲线下的面积（定积分），矩形分割得越细则估计越准确。如果过大，则不准。因此，当$\epsilon$小时，需要更长的时间sampler才能到达离初始位置更远的地方，也会降低采样效率。&lt;/p&gt;
&lt;p&gt;对L参数的影响，应该结合$\epsilon$来看。$\epsilon$控制了一次迭代内对Hamilton&amp;rsquo; equations近似的精确程度。而L*$\epsilon$控制了采样器偏移初始点的距离。这个距离并不是绝对的距离，而是一整个迭代中采样器游走的距离。假设L*$\epsilon$设置得较大，会有不良影响。考虑两种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;初始值离mode较近，此时较大的L*$\epsilon$，或T，可能让sampler对mode和初始值过度采样。当动能方向偏离mode时，由于T过长，q*可能又从偏离初始值的位置游走回初始值，从而使得对初始值过度采样。当动能方向朝向mode时，由于时间长，往往停留在mode，导致对mode过采样，对周围typical set采样不足。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;初始值离mode较远，动能方向远离mode时，如上述1情况对初始值过度采样。动能朝向mode时，往往会穿过mode，使得对mode和周围高密度区域采样不足。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上两种情况，说明L*$\epsilon$过大，以至于在相空间内出现了转弯，即U-Turn的情况，严重影响了采样效率。因此一种HMC的variant，No-U-Turn Sampler (NUTS)，应运而生。NUTS主要对L进行了适应性调整。在每一次iteration中，当p和当前step移动的距离的点乘为负值时，结束leapfrog。这说明当出现U-Turn时（点乘小于0说明夹角在90-180°）结束本次模拟。此外，NUTS还对$\epsilon$和$\bold{M}$进行了适应性调整。&lt;/p&gt;
&lt;p&gt;对$\bold{M}$，NUTS会在warm up阶段进行适应性调整，使其接近posterior的协方差矩阵。如果$\bold{M}$选得较宽，则proposal distribution也会较宽，反之亦然。第一次读到这里会产生疑惑，既然$\bold{M}$和$\epsilon$都控制了采样器移动的step size，为什么不固定$\bold{M}$，而只调整$\epsilon$呢？回头看leapfrog的公式，第二步中$\bold{M}^{-1}$前面确实乘了一个$\epsilon$。&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;p&gt;Betancourt, M. (2017). A conceptual introduction to Hamiltonian Monte Carlo. arXiv preprint arXiv:1701.02434.&lt;/p&gt;
&lt;p&gt;Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp;amp; Rubin, D. B. (2014). Bayesian Data Analysis. Bayesian Data Analysis.&lt;/p&gt;
&lt;p&gt;Hoff, P. D. (2009). A first course in Bayesian statistical methods (Vol. 580). New York: Springer.&lt;/p&gt;
&lt;p&gt;Kruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan.&lt;/p&gt;
&lt;p&gt;Lambert, B. (2018). A student&amp;rsquo;s guide to Bayesian statistics. A Student&amp;rsquo;s Guide to Bayesian Statistics, 1-520.&lt;/p&gt;
&lt;p&gt;Matsuura, K. (2023). Bayesian Statistical Modeling with Stan, R, and Python. Springer.&lt;/p&gt;
&lt;p&gt;McElreath, R. (2018). Statistical rethinking: A Bayesian course with examples in R and Stan. Chapman and Hall/CRC.&lt;/p&gt;
&lt;p&gt;Nicenboim, B., Schad, D., &amp;amp; Vasishth, S. (2021). An introduction to Bayesian data analysis for cognitive science. Under contract with Chapman and Hall/CRC statistics in the social and behavioral sciences series.&lt;/p&gt;
&lt;p&gt;Vehtari, A., Gelman, A., &amp;amp; Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC.         Statistics and computing, 27, 1413-1432.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>重复测量设计中的效应量</title>
        <link>https://Junsong798.github.io/p/effect-size-metric/</link>
        <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
        
        <guid>https://Junsong798.github.io/p/effect-size-metric/</guid>
        <description>&lt;img src="https://Junsong798.github.io/p/effect-size-metric/fig1.jpeg" alt="Featured image of post 重复测量设计中的效应量" /&gt;&lt;h2 id=&#34;两种效应量量纲&#34;&gt;两种效应量量纲&lt;/h2&gt;
&lt;p&gt;在新的元分析中，发现不少实验是within-subject design，时隔一年多，不少计算细节已经记得不清楚，比如如何统一不同scaling下效应量的量纲，如何选择量纲，以及不同量纲之间sampling variance如何计算。回忆2021年4月15号的小组会议。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;21点多开完会，想起老师下午给了我一袋零食，准备吃一口，一看生产日期&amp;hellip;.2019.10，保质期365天。原来老师是想毒死我。&lt;/p&gt;
&lt;p&gt;晚上的会议一上来我就让小姚讲一讲d效应量的两种scaling，以及不同学者在面对paired t test时公式的等价性和假定。当然，简单看了看几篇统计论文后，我大概搞清楚了一件事情，几种效应量，重复测量与独立测量的方法，必须满足复合对称性（compound symmetry）才能在标度上等价。以及，我还清楚，Borenstein的重复测量效应量，基于方差齐性假定。另外，Morris和Borenstein的公式似乎是等价的，只不过差一个转换。&lt;/p&gt;
&lt;p&gt;小姚同学上来就纠正我，两者定义似乎分母差了一个根式，于是我当场短路。小匡同学直接挪过黑板做了公式的推导，速度过快以至于我差点没看懂，全组8个同学只有我们三个在讨论，其他同学逐渐淡出背景。最后的结论是，Morris和Borenstein都假定了方差齐性，但是其相关系数的近似其实是严格从t效应量中推导得出，因此并不是近似，而是要求重复测量下要么知道前后测，要么知道相关和差值的标准差才能计算。后者不需要假定方差齐性，假定齐性时两者等价。&lt;/p&gt;
&lt;p&gt;&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;p&gt;另外两个问题极为有趣，即partial eta square如何转换为Fisher&amp;rsquo;s Z, 我和小姚表示一脸懵逼。小匡说，直接对partial eta square开根号得到Pearson&amp;rsquo;s r，再转z。我反驳说，此时的eta square严格等价为partial correlation，开根后不严格等价，小姚学弟表示赞同。然后小匡推了一个partial correlation的公式，说现有论文信息不足，基本只能近似，许多在线网站的运算逻辑都是如此。我表示大家统计学得太好，不如开发个R包，吊打世界算了。&lt;/p&gt;
&lt;p&gt;最后的问题是beta coefficient向z的转换，Peterson和Brown的模拟研究表明，r = β + 0.05λ。其中λ取决于β正负号。我提出，在一篇人类学期刊中，我用β近似的相关极大，而且β本身大于1很多，虽然在强烈的multicollinearity的情况下这是可能的。小匡立即给出了用β近似X和Y之间covariance的严格推导，并指出其不可行性。我则指出这就是为什么很多回归会有suppression effect，因为第一个β的效应被其他变量的系数所抵消。极端情况下，这种近似方法会有偏差。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首要明确的一点，现有心理学大部分元分析在method部分并没有强调效应量的scaling。实际上，大家都心照不宣地采用了Jacob Cohen定义的效应量，即Cohen&amp;rsquo;s d的scaling。这个scaling被定义为independent-groups effect size，即常见的被试间设计得到的效应量。这个scaling也同理拓展到r family效应量上，比如point-biserial correlation。&lt;/p&gt;
&lt;p&gt;计算Cohen&amp;rsquo;s d的方法是，由给定的t统计量剥离样本量得到。一个简单的例子，假定homogeneity of variance以及balanced design，公式为：&lt;/p&gt;
&lt;p&gt;$t = d * \sqrt[]{\frac{n}{2}}$&lt;/p&gt;
&lt;p&gt;此时，效应量$d$的公式为：&lt;/p&gt;
&lt;p&gt;$\frac{\bar{X_1}-\bar{X_2}}{s_p}$&lt;/p&gt;
&lt;p&gt;但如果是前后侧的被试内设计，HOV假定下得到的t统计量（paired t）实际上分解为：&lt;/p&gt;
&lt;p&gt;$t=\frac{\bar{X_1}-\bar{X_2}}{s}*\sqrt{n} *\sqrt{\frac{1}{2(1-r)}}$&lt;/p&gt;
&lt;p&gt;剥离样本量后，得到的$d$为：&lt;/p&gt;
&lt;p&gt;$d=\frac{\bar{X_1}-\bar{X_2}}{s} *\sqrt{\frac{1}{2(1-r)}}$&lt;/p&gt;
&lt;p&gt;注意这里为什么是去除$\sqrt{n}$而不是$\sqrt{n/2}$，因为paired t test和independent t test是两种不同的检验，前者本质上是单样本检验，而后者是双样本检验。对单样本检验，中心统计量$\delta$和效应量的关系为：&lt;/p&gt;
&lt;p&gt;$\delta = d * \sqrt{n}$&lt;/p&gt;
&lt;p&gt;这里依然满足导出$d$时，效应量的含义是“两个总体均值相差的标准差的个数”。虽然看起来两种t统计量还原出的$d$都是均值之间差了几个标准差，但是由于单双侧检验在标准差的scaling上不同，导致了两个效应量scaling的不同。对independent t来说，其标准差是raw score的标准差，比如实验组因变量观测值的标准差。而paired t的标准差是分数差值的标准差：&lt;/p&gt;
&lt;p&gt;$t_{RM}=\frac{\bar{D}}{\frac{S_{D}}{\sqrt{n}}}$&lt;/p&gt;
&lt;p&gt;因此，对paired t得出的$d$，应该解释为：相对于0点，平均改变了$d$个标准差，即：&lt;/p&gt;
&lt;p&gt;$d=\frac{\bar{X_1}-\bar{X_2}}{s} *\sqrt{\frac{1}{2(1-r)}}=\frac{\bar{X_1}-\bar{X_2}}{S_{D}}$&lt;/p&gt;
&lt;p&gt;如果上述式子不明显，参考以下步骤，即可得知差值的标准差和raw score的标准差的关系：&lt;/p&gt;
&lt;p&gt;$t_{RM}=\frac{\bar{D}}{\frac{S_{D}}{\sqrt{n}}}=\frac{\bar{D}}{\sqrt{\frac{s_1^2+s_2^2}{n}-\frac{2&lt;em&gt;r&lt;/em&gt;s_1*s_2}{n}}}$&lt;/p&gt;
&lt;p&gt;如果HOV满足，则：&lt;/p&gt;
&lt;p&gt;$t_{RM}=\frac{\bar{D}}{\sqrt{\frac{s_1^2+s_2^2}{n}-\frac{2&lt;em&gt;r&lt;/em&gt;s_1*s_2}{n}}}=\frac{\bar{D}}{\sqrt{\frac{2s^2(1-r)}{n}}}$&lt;/p&gt;
&lt;p&gt;从而得到两种标准差的转换公式：&lt;/p&gt;
&lt;p&gt;$S_{D}=S\sqrt{2(1-r)}$&lt;/p&gt;
&lt;p&gt;同理，得到效应量两种量纲的转换公式：&lt;/p&gt;
&lt;p&gt;$d_{RM}=d_{IG}/\sqrt{2(1-r)}$&lt;/p&gt;
&lt;h2 id=&#34;效应量的计算&#34;&gt;效应量的计算&lt;/h2&gt;
&lt;p&gt;最常见的情况，由t统计量导出。&lt;/p&gt;
&lt;p&gt;对independent t test，更一般的情况，如不平衡设计，那么可以得到：&lt;/p&gt;
&lt;p&gt;$d = t * \sqrt[]{\frac{n_1+n_2}{n_1n_2}}$&lt;/p&gt;
&lt;p&gt;对paired t test，如上部分所述，有：&lt;/p&gt;
&lt;p&gt;$d = \frac{t} {\sqrt{n}}$&lt;/p&gt;
&lt;p&gt;另一种情况，已知两组的mean和sd，估计效应量。对independent t，可以假定HOV计算出t，再计算$d$，但对paired t而言，需要额外知道两次观测的相关系数。&lt;/p&gt;
&lt;p&gt;根据paired t的公式，在已知前后侧标准差，差值的标准差时，可以严格计算相关系数：&lt;/p&gt;
&lt;p&gt;$r = \frac{SD_{pre}^2+SD_{post}^2-SD_{D}^2}{2SD_{pre}SD_{post}}$&lt;/p&gt;
&lt;p&gt;若前后侧不知道，那么假定前后侧方差齐性，用联合总体标准差估计即可，得到：&lt;/p&gt;
&lt;p&gt;$r = 1-\frac{SD_{D}^2}{2SD_{pooled}^2}$&lt;/p&gt;
&lt;p&gt;然而，研究往往不会报告差值的标准差，所以需要进行计算：&lt;/p&gt;
&lt;p&gt;$SD_{D}^2=\frac{n(M_{post}-M_{pre}^2)}{t^2}$&lt;/p&gt;
&lt;p&gt;得到差值的标准差后，再代入上述的两个公式，即可得到r。但更常见的，如果前后侧标准差也没报告，往往需要元分析的作者假定一个相关系数，比如0.5，才能继续计算效应量。&lt;/p&gt;
&lt;h2 id=&#34;效应量的抽样误差&#34;&gt;效应量的抽样误差&lt;/h2&gt;
&lt;p&gt;效应量的sampling variance用于计算单个研究的权重，以此进行元分析的加权。对被试间设计，效应量的抽样误差取决于样本量和效应量本身，其近似公式为：&lt;/p&gt;
&lt;p&gt;$V_d=\frac{n_1+n_2}{n_1n_2}+\frac{d^2}{2(n_1+n_2)}$&lt;/p&gt;
&lt;p&gt;推导过程见&lt;a class=&#34;link&#34; href=&#34;https://stats.stackexchange.com/questions/144084/variance-of-cohens-d-statistic&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;cross validated&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;而对配对样本，除了样本量，抽样误差还取决于匹配情况，如相关系数的大小。采用raw score作为效应量scaling时，可以用Morris和Deshon提出的通用转化公式：&lt;/p&gt;
&lt;p&gt;$\sigma_{e_i}^2=\frac{A^2}{\tilde{n}}\frac{df}{df-2}(1+\frac{\tilde{n}}{A^2}\sigma_{&lt;em&gt;}^2)-\frac{\delta_{&lt;/em&gt;}^2}{c^2}$&lt;/p&gt;
&lt;p&gt;其中df为对应设计的自由度，A代表两种效应量之间的转换公式，如果用raw score scaling，则A为：&lt;/p&gt;
&lt;p&gt;$A=\sqrt{2(1-p)}$&lt;/p&gt;
&lt;p&gt;而$\tilde{n}$为一个与样本量有关的系数，类似有效样本量。如果是被试间设计，则：&lt;/p&gt;
&lt;p&gt;$\tilde{n}=\frac{n_1n_2}{n_1+n_2}$&lt;/p&gt;
&lt;p&gt;如果是匹配设计，则等于样本数：&lt;/p&gt;
&lt;p&gt;$\tilde{n}=n$&lt;/p&gt;
&lt;p&gt;此外，c为一个与自由度有关的函数，也是用来矫正$d$的大小的函数：&lt;/p&gt;
&lt;p&gt;$c(df) = 1 - \frac{3}{4df-1}$&lt;/p&gt;
&lt;p&gt;因此，假如一个研究是被试内设计，而元分析的scaling是raw score，那么首先计算出$d_{RM}$并转换为raw score下的$d_{IG}$，然后用以下公式计算抽样误差：&lt;/p&gt;
&lt;p&gt;$\sigma_{e_i}^2=\frac{2(1-r)}{n}\frac{n-1}{n-3}(1+\frac{n}{2(1-r)}d_{IG}^2)-\frac{d_{IG}^2}{c^2}$&lt;/p&gt;
&lt;h2 id=&#34;效应量标度的选择&#34;&gt;效应量标度的选择&lt;/h2&gt;
&lt;p&gt;效应量的scaling取决于研究者希望回答的问题。如果一个元分析希望知道一种实验处理的组间差异——处理效应的差异是否存在，用raw score metric更好。如果研究者关心的是在一系列successive trials间被试自身的变化，那么change score metric更好。&lt;/p&gt;
&lt;p&gt;@MorrisImpulsivitymediatingfactor2020&lt;/p&gt;
</description>
        </item>
        <item>
        <title>囫囵吞枣之现代稳健估计方法</title>
        <link>https://Junsong798.github.io/p/robust-statistics/</link>
        <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
        
        <guid>https://Junsong798.github.io/p/robust-statistics/</guid>
        <description>&lt;img src="https://Junsong798.github.io/p/robust-statistics/fig_caption.jpg" alt="Featured image of post 囫囵吞枣之现代稳健估计方法" /&gt;&lt;p&gt;历经60多个小时，我设计的非线性元分析方法模拟终于结束，在这半个月中，快速扫读了不少现代统计的教材和论文，收获颇丰，简单谈谈感想。&lt;/p&gt;
&lt;p&gt;在心理学人中间，流传着这样一句话：F检验，或者ANOVA，是稳健的。比如，我向无数学弟学妹强推的纽大心理学教授写的《Explaining psychological statistics》中就强调了这一点。稳健，或者鲁棒性，数学定义繁多，心理学人常常理解为对正态假定的偏离不影响假设检验，姑且这么理解。&lt;/p&gt;
&lt;p&gt;现实情况又如何呢？问题可以追溯到1960年，Tukey发表的一篇现代统计里程碑之作。在论文中，Tukey定义了mixed normal distribution，或者更带感情色彩的术语，contaminated distribution。他指出，目前基于均值的统计方法，即使仅仅small departure from normal，都会对假设检验造成灾难。Tukey的论文并没有很快对应用统计产生影响，因为时代背景下，缺乏特定的统计理论和工具。但这篇论文成为了后来研究的催化剂，使得Huber和Hampel两位后来的领域奠基人开始着手于稳健理论的开发。实际上，这并不是对正态假定的第一次挑战。早在1954年，Box就指出，当两个抽样群体来自异方差的两个正态分布，会对Type I error的概率产生极大影响。但因其论文数学繁杂，并没有让太多统计学家认识到基于正态假设统计方法的弊端。接着，1972年，心理学人再熟悉不过的统计学家Glass，也就是meta-analysis的创始人，与其同事发表论文，阐述了经典统计方法，t test和ANOVA，在异方差下的不稳健性，并建议将其“废除”（abandon）。半个世纪后，稳健统计得到长足发展，并使得现代方法与基于正态假定的统计检验在诸多表现上差距巨大。然而，他们并没有在社会科学研究中占据高地，原因有三：&lt;/p&gt;
&lt;p&gt;第一个原因来自统计领域，当时缺乏稳健性理论和对稳健性的系统定义，进而是对随机抽样下，对总体统计量的有效性更好的推断方法尚为萌芽阶段。这使得整个领域发展周期更长，如果把一个科研领域分解为范式批判，范式转移，范式建立，再到应用，目前的稳健统计发展还没有到达最后的阶段。&lt;/p&gt;
&lt;p&gt;其二，20世纪后半叶，更快运算速度的计算机开始普及，为重复抽样和建模提供了便利，极大重塑了统计学领域。统计学家们这才发现，19世纪的统计学在时代洪流中只能作为前人的历史游戏而存在。&lt;/p&gt;
&lt;p&gt;最后的问题在于统计领域和社会科学之间的沟通桥梁。现代统计的数学极为繁琐，并非接受常规研究方法训练的心理学研究者能轻松理解，加上一些社会科学，以心理学特为尤甚，常常不为学生设计专门的统计学课程，在教学过程中不讲授matrix calculus和数理统计基础，使得统计退化为一种不存在思考的固有程序。&lt;/p&gt;
&lt;p&gt;如果能在课堂上普及传统方法的弊端（不仅仅是非正态性的影响），那么对新方法的探究和应用就会变得刻不容缓。以下先探讨两个最简单，也是最容易在心理学研究中遇到的问题，第一个讲混合正态分布对假设检验的影响，第二个讲用不同稳健性定义来看OLS estimator，会有哪些弊端。&lt;/p&gt;
&lt;p&gt;混合正态分布，可以理解为一种边缘分布。假设随机变量X服从参数分布F，而F具有参数θ，服从某一种分布G（潜变量分布，未观测到的分布）。所以，可以直观地把X的分布理解为X和θ联合分布的积分，即一种边缘分布。注意，这个概念等价于不同正态分布的叠加，此时结果往往不是正态分布。切勿将其理解为正态随机变量的叠加，其结果为正态分布。&lt;/p&gt;
&lt;p&gt;混合分布对假设检验的直接影响是可能大幅度提高样本均值标准误，并大幅度削弱power。考虑这样的情况，一个心理学家测量心理变量X，但其抽样的总体是被污染的。他假定所有样本都没有精神分裂症，且总体服从N(0,1^2), 但该总体中存在10%的患者，在X上服从N(0, 10^2). 此时的混合分布具有长尾且不服从正态，同时将方差扩大到原先的10.9倍。这使得凡是基于标准差的统计量，比如标准误，受到大幅影响，进而巨幅降低power。更糟糕的是，即使用于检验的两个独立样本都来自钟形曲线，且均值方差相等，其概率密度函数依然可以极大偏离正态分布。这使得基于总体正态分布的检验方法，如小样本时的t分布，在假设检验时面临灾难。&lt;/p&gt;
&lt;p&gt;回到心理学，这个问题有多大可能出现？心理学家argue道，CLT中心极限定理告诉我们，大量独立随机变量均值适当标化后依分布收敛于正态（作为一种illustration，也见高尔顿的钉板和图灵奖得主Judea Pearl的教材）。而且只要样本够大，CLT保证了我们的样本的抽样分布，比如均值分布，渐进正态。&lt;/p&gt;
&lt;p&gt;然而现实中的人类心理并非如此，三个方面。第一，CLT强调的是效应相加，而非相乘。现实世界中更常见的是代表相乘效应的幂律分布，比如马太效应，这可以体现在GPA的分布上（当然指数和对数变换是心理学研究者常常误用的统计方法，详情见各种feature engineering教材）。第二，心理学无法做到随机抽样，都是通过招募，或者是由实验设计决定了目标群体，比如肥胖症患者，各种心理疾病人群，发展心理学研究中的不同年龄组，不同经济地位组，使得正偏态更为常见。第三，我们很大程度上无法确定我们获得的分布是不是混合正态。&lt;/p&gt;
&lt;p&gt;因此，在做最简单的统计检验，比如均值差异时，心理学研究者需要保证其统计方法具有至少两个优势：其一，因变量的集中趋势不应该对概率曲线敏感，比如median敏感性比mean差很多（这里的说法类似传统的qualitative robustness的定义，描述总体统计量的函数，在分布改变时等度连续。请参考Huber2009年和Wilcox2017年的教材）；其二，非正态和混合正态下，统计检验力和标准误不会比正态下有明显变化。&lt;/p&gt;
&lt;p&gt;第二个例子是OLS回归，其后果可以引申到一切类似方法，比如积差相关，逐步、分层回归，路径分析。OLS的问题可以从quantitative robustness的定义看出。Quantitative robustness，一般用有限样本屈服点来界定（finite sample breakdown point）。假设存在混合分布，其中代表异常点的分布在抽样中的比重是c，则异常分布的均值趋于无穷时，让混合分布均值趋于无穷的最小c值，则为屈服点。更简单，更一般的表述是，一种统计量，可以容忍多少个异常值。以此视角，样本均值的屈服点是1，OLS回归的屈服点也是1. 因为任何一个无限大的异常值都可以影响参数估计。OLS的问题是，无论这个异常点来自于因变量（异常值），还是自变量（高杠杆点），都会有巨大影响。&lt;/p&gt;
&lt;p&gt;从一种高屋建瓴的模型角度来理解，则更为清晰。我在给心理学本科生做家教的课件时，曾经写了一般线性模型之间等价关系的证明，即独立t，ANOVA，积差相关，回归，ANCOVA的检验在数学上等价，可惜并没有时间讲。如果从模型的角度，求解样本中心趋势，和求解回归，目标函数是一样的。对求解均值，最小化目标函数是样本的二阶中心矩，然后对其求一节条件，便是均值。而对OLS回归，形式完全不变。所以二者屈服点必为一致。 对二者来说，初始的目标函数都是一个二次函数，这使得异常值以指数对目标函数产生影响。&lt;/p&gt;
&lt;p&gt;回头反思心理学领域的统计应用，为什么基于最小二乘的方法依然大行其道？因为大家从来不做模拟，不知道基于least squares的方法在估计SE和回归系数时有多么不准确。更多的，是因为社科领域重视解释而非预测，所以对总体参数的估计不太在意，只关注关系是否显著。但显著性恰恰是建立在准确的标准误之上的。&lt;/p&gt;
&lt;p&gt;如上所述，对于OLS estimator的改进可能已经暗示得很明显了。如果目标函数是一个二次函数，那么只需要限制异常值对这个目标函数的影响速率，是不是就可以了？这就是最早M-estimator的由来。M估计量首先定义了一个可微函数，描述了集中趋势到其他点的距离，接着，对这个函数微分，令其期望等于0则可求解出该目标函数下的集中趋势。这也暗示着，均值和OLS是M估计量的一种特例。如果采用Huber&amp;rsquo;s \Psi，可以将目标函数改为一个中间是二次函数，两端是一次函数的曲线，这使得样本两端的点被适当降权，减弱了对目标函数的影响。&lt;/p&gt;
&lt;p&gt;当然，如果这么来看，Huber提出的函数并没有提高屈服点，因为即使是线性增加，依然在该异常点趋于无穷时，有无穷大影响。这种早期函数也被后来的新方法取代，比如MM-estimator。&lt;/p&gt;
&lt;p&gt;总结，现代稳健方法的发展似乎呈现如下趋势：首先是基于模拟找出传统方法的弊端，比如估计量的低power，低efficiency，进而寻找概念去描述这种不稳健特性。三个经典的概念是qualitative，quantitative，and infinitesimal robustness。基于这些概念，统计学家开始建立稳健统计理论并寻找稳健估计方法。因为当一种传统方法被稳健概念描述后，可以清晰地知道其问题缘由。比如，发现OLS的低屈服点，那么就去构造高屈服点的estimator；再比如，根据qualitative robustness，要求找到估计量在分布改变时等度连续，或者导数有界。概念之所以重要，是因为他是后续研究的思路，决定了方法如何建立。再之后，就是用计算机进行模拟实验，测试性能。得到稳定的结果后，封装程序，开枝散叶，把统计方法传播到其他应用领域。&lt;/p&gt;
&lt;p&gt;所以，如果一名统计学门外汉（指没有上过专门的统计课，比如笔者这样的人）想要掌握一些基础的现代统计方法，建议按照上述领域发展的进程去学习概念，再用心理学或者其他领域的数据去实践。推荐的作者是Wilcox, Huber, Hampel, Hox等人的教材，tutorial和论文。尤其是Wilcox引用最高的书，可以花1-2天快速扫读一遍。先知道稳健性的数学定义，然后去看集中趋势和散度的估计方法，再到两样本检验，进而到更一般的回归。由于某些统计方法，如M-estimator回归的标准误是渐进方法，因此标准误并非所有情况下都会准确，所以也要搭配区间估计的稳健方法。最后，统计软件推荐R而非python，因为py相关的库还是太少了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Junsong798.github.io/p/robust-statistics/robust2.png&#34;
	width=&#34;950&#34;
	height=&#34;546&#34;
	srcset=&#34;https://Junsong798.github.io/p/robust-statistics/robust2_hu3f287108adcf3e9070e1f6caf0c2dcdb_13176_480x0_resize_box_3.png 480w, https://Junsong798.github.io/p/robust-statistics/robust2_hu3f287108adcf3e9070e1f6caf0c2dcdb_13176_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;HC3标准误模拟结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;417px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>真实世界的心理模型</title>
        <link>https://Junsong798.github.io/p/%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%BF%83%E7%90%86%E6%A8%A1%E5%9E%8B/</link>
        <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
        
        <guid>https://Junsong798.github.io/p/%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%BF%83%E7%90%86%E6%A8%A1%E5%9E%8B/</guid>
        <description>&lt;img src="https://Junsong798.github.io/p/%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E7%9A%84%E5%BF%83%E7%90%86%E6%A8%A1%E5%9E%8B/causal1.png" alt="Featured image of post 真实世界的心理模型" /&gt;&lt;p&gt;2020年12月21日，《自然》撤稿了一篇一作为女性科学家的论文——The association between early career informal mentorship in academic collaborations and junior author performance，原因是违反科学实验协议以及错误地解读数据。该论文声称学界逐渐增长的女性导师会破坏女性科学家职业生涯初期的影响力。论文一经发布便引来口诛笔伐，替代计量引用迅速飙升。抛开文章结论，我们不禁要问：是什么阻碍了研究者从数据中得到真相？以及何种情况下，数据才能为假设提供证据？&lt;/p&gt;
&lt;p&gt;时间来到1973年，加州大学副院长Hammel发现，申请伯克利研究生的男生中，有44%被录取了，而女生录取率只有35%。然而，当Hammel对每个院系进一步分析时，却发现所有院系的录取都是女生更高。为了明辨事实，避免遭受性别歧视的控诉，Hammel找来了Bickel分析数据，后者在1984年拿到麦克阿瑟天才奖，但彼时不过是一名初出茅庐的统计研究者。Bickel一眼就认出了数据中的辛普森悖论——在总体和亚组层面，数据呈现出截然相反的结论。&lt;/p&gt;
&lt;p&gt;1975年，Bickel和Hammel等人在《科学》发表论文“sex bias in graduate admissions: data from Berkeley”，用因果层面的解释给出了辛普森悖论的解法：在总体层面，女性申请者被拒绝的比率更高，是因为她们更倾向于申请更难录取的人文与社科学科。这一解法有其合理性，因为辛普森悖论中正确的结论取决于特定的研究问题和研究假设。在伯克利招生悖论中，性别以学院为中介，作用于录取结果（当时路径分析体系还未被统计界认可）。因此性别歧视的合理定义应为性别对录取结果的直接，而非总效应。我们知道，计算直接效应，需要控制中介，意味着对性别分层，在亚组内考虑结论。因此伯克利是清白的。&lt;/p&gt;
&lt;p&gt;但是故事到这里远未结束。当时大名鼎鼎的统计学家，如今广泛应用的非参数ANOVA的提出者，Kruskal，给Bickel等人发了一封质疑信。在通信中，Kruskal用假象数据限制了Bickel的结论：如果一个大学有两个存在性别歧视的院系，他们都接受所有本州男性和外州女性的申请，但拒绝所有外州男性和本州女性，仍然可以得到与Bickel手头一样的数据。此时，真实存在的性别歧视不再为中介模型所求出，何解？套用因果推断的术语，变量“院系”和“录取结果”中再次打开了一条后门路径，经由院系到居住州，再到录取结果，而居住州是二者的共同因。当数据集中不包含“居住州”时，控制院系而不控制居住州，得到的性别效应依然不是直接效应，而是直接效应和后门路径的效应。&lt;/p&gt;
&lt;p&gt;因为时代背景下，缺乏特定的数学工具，Bickel在回复中无力解释质疑。Kruskal的评论在今天看来依然一针见血，对心理学以及其他社科研究依然由重要意义：在协方差分析中，一个研究者应该控制哪些变量；在路径分析中，必须放入哪些变量？这个问题的答案，对结论的正确性有着决定性的意见。&lt;/p&gt;
&lt;p&gt;实际上，每一个受过良好统计学训练的心理学研究生，都已经在课上学到了这些问题的回答：基于理论得出图结构假设，再用数据支持；同时，必须在路径分析中放入混淆变量以免极大程度影响路径系数等。问题在于，人们往往忽视了一点，即结论的可靠性，首要取决于先验的因果理论，其次才是数据——数据很蠢，不会自己告诉我们结论。而现实中，人们倾向于把理论研究的问题，归咎于统计问题。&lt;/p&gt;
&lt;p&gt;1920年，赖特在PNAS上发表了一篇进化生物学上里程碑式的论文，论文中，他第一次采用了一种被称为路径图的结构，用于探究遗传因子对小鼠毛色变异的影响强度。其方法的依据是，通过理论勾勒出现实世界的因果关系，再求解变量之间相关性，从而得到因果性的结论。一年后，赖特系统地总结了他的方法，发表了一篇名为correlation and causation的论文。要知道，当时的统计学界，将因果视为伊甸园的苹果，唯恐避之不及。&lt;/p&gt;
&lt;p&gt;纵观历史，科学的发展中充斥着霸权主义以及以温文尔雅为表象的野蛮行径。皮尔逊的徒孙Pearl立即对赖特的方法论回应，并在论文中指出：the basis of the method of path coefficients is faulty. 与此同时，当时学界的领袖Fisher也将赖特视为自己的敌人，崇尚简约的统计学——统计学是一种收集数据并按照固定程序分析的科学。时间悄然而逝，63年之后的1983年，93岁高龄的赖特再次被学术界推上风口浪尖，不得不再次提笔，在遗传学期刊上回应数学家们对路径分析的批评——在这之间，他的理论本应是发展壮大。&lt;/p&gt;
&lt;p&gt;赖特的理论在今天看来为什么是合理的？因为路径分析要求研究者不能服从一种固定的程式，而是对特定的研究以图形的方式提出特定的因果关系——概念，再辅以真实世界的数据进行验证——经验，从而从不同的信息源对客观真理进行验证。而这种思想并未被大众所理解，这使得路径分析在20实际后半叶走向了分水岭，一方面是心理学家和社会学家们结合验证性因素分析将其发展为结构方程模型（SEM）。伴随着LISREL的诞生，数据分析由不同信息源的交叉验证沦为软件使用，人们不再过问数据背后的真相；一方面，经济学家们发展了联立方程模型，彻底舍弃了路径图，不再考虑先验的理论意义。&lt;/p&gt;
&lt;p&gt;时至今日，因果已经不再是统计界的禁忌，因果已经完成了从哲学含义到数学定义的转变，并有了专门的研究方向。显赫的成果，有贝叶斯网之父Pearl的因果识别研究，有卡内基梅龙团队的因果搜寻，也有Rubin的潜在结果模型。在因果搜寻算法层面，总体呈现出三个方向：一种是90年代兴起，由CMU团队发展的条件独立算法，经典的是PC，以及有潜在共同因时的FCI算法；一种是基于数据全局结构发掘因果关系的GES算法；最后一类是基于特定残差假定的函数式因果模型，典型的方法有LiNGAM，并搭载了基于ICA，或者是回归的独立性判定方法。&lt;/p&gt;
&lt;p&gt;我们不禁要问，既然因果已经完成数学化，那么为什么学界依然面临因果关系的困境？或者说，如果把一个形而上学问题数学化并用公式表述，且发现数据符合该数学形式，为什么依然说认识论无法回答本体论问题? 结论是，因为数据符不符合数学表达是根据假设检验决定的，中间的决策是基于统计学不是数学，而统计是对客观真理的推测，总有出错可能，所以不能给出形而上学问题的回答。抛开少数因果方向不可识别的几种情况，抛开时序变化因果关系，我们知道的是，不同的算法会有其固有缺陷。比如PC算法由于其按数据集顺序抓取变量计算条件独立，极端情况下受到数据集变量顺序影响；此外，PC还受潜在共同因影响、在小样本时不满足因果充要条件。另外，在统计决策的层面，我们会面临一二三类错误。至少，我们还会面临测量变量有噪声的情况，测量变量呈现出难以处理的偏态分布或者因为抽样不当导致的混合高斯分布。更根本的问题是，我们无法先验地判断数据更符合哪种模型的假设，从而无法解释方法之间输出的因果图的差异。一方面，这促进了因果学习领域百花齐放的局面，一方面，又将人们固有的“拿到数据，放下汲桶，真相俯拾可得”的白日梦推向覆灭。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
