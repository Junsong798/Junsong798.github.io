<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>科学史 on Junsong Lu</title>
        <link>https://Junsong798.github.io/categories/%E7%A7%91%E5%AD%A6%E5%8F%B2/</link>
        <description>Recent content in 科学史 on Junsong Lu</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Sun, 31 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://Junsong798.github.io/categories/%E7%A7%91%E5%AD%A6%E5%8F%B2/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>囫囵吞枣之现代稳健估计方法</title>
        <link>https://Junsong798.github.io/p/robust-statistics/</link>
        <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
        
        <guid>https://Junsong798.github.io/p/robust-statistics/</guid>
        <description>&lt;img src="https://Junsong798.github.io/p/robust-statistics/fig_caption.jpg" alt="Featured image of post 囫囵吞枣之现代稳健估计方法" /&gt;&lt;p&gt;历经60多个小时，我设计的非线性元分析方法模拟终于结束，在这半个月中，快速扫读了不少现代统计的教材和论文，收获颇丰，简单谈谈感想。&lt;/p&gt;
&lt;p&gt;在心理学人中间，流传着这样一句话：F检验，或者ANOVA，是稳健的。比如，我向无数学弟学妹强推的纽大心理学教授写的《Explaining psychological statistics》中就强调了这一点。稳健，或者鲁棒性，数学定义繁多，心理学人常常理解为对正态假定的偏离不影响假设检验，姑且这么理解。&lt;/p&gt;
&lt;p&gt;现实情况又如何呢？问题可以追溯到1960年，Tukey发表的一篇现代统计里程碑之作。在论文中，Tukey定义了mixed normal distribution，或者更带感情色彩的术语，contaminated distribution。他指出，目前基于均值的统计方法，即使仅仅small departure from normal，都会对假设检验造成灾难。Tukey的论文并没有很快对应用统计产生影响，因为时代背景下，缺乏特定的统计理论和工具。但这篇论文成为了后来研究的催化剂，使得Huber和Hampel两位后来的领域奠基人开始着手于稳健理论的开发。实际上，这并不是对正态假定的第一次挑战。早在1954年，Box就指出，当两个抽样群体来自异方差的两个正态分布，会对Type I error的概率产生极大影响。但因其论文数学繁杂，并没有让太多统计学家认识到基于正态假设统计方法的弊端。接着，1972年，心理学人再熟悉不过的统计学家Glass，也就是meta-analysis的创始人，与其同事发表论文，阐述了经典统计方法，t test和ANOVA，在异方差下的不稳健性，并建议将其“废除”（abandon）。半个世纪后，稳健统计得到长足发展，并使得现代方法与基于正态假定的统计检验在诸多表现上差距巨大。然而，他们并没有在社会科学研究中占据高地，原因有三：&lt;/p&gt;
&lt;p&gt;第一个原因来自统计领域，当时缺乏稳健性理论和对稳健性的系统定义，进而是对随机抽样下，对总体统计量的有效性更好的推断方法尚为萌芽阶段。这使得整个领域发展周期更长，如果把一个科研领域分解为范式批判，范式转移，范式建立，再到应用，目前的稳健统计发展还没有到达最后的阶段。&lt;/p&gt;
&lt;p&gt;其二，20世纪后半叶，更快运算速度的计算机开始普及，为重复抽样和建模提供了便利，极大重塑了统计学领域。统计学家们这才发现，19世纪的统计学在时代洪流中只能作为前人的历史游戏而存在。&lt;/p&gt;
&lt;p&gt;最后的问题在于统计领域和社会科学之间的沟通桥梁。现代统计的数学极为繁琐，并非接受常规研究方法训练的心理学研究者能轻松理解，加上一些社会科学，以心理学特为尤甚，常常不为学生设计专门的统计学课程，在教学过程中不讲授matrix calculus和数理统计基础，使得统计退化为一种不存在思考的固有程序。&lt;/p&gt;
&lt;p&gt;如果能在课堂上普及传统方法的弊端（不仅仅是非正态性的影响），那么对新方法的探究和应用就会变得刻不容缓。以下先探讨两个最简单，也是最容易在心理学研究中遇到的问题，第一个讲混合正态分布对假设检验的影响，第二个讲用不同稳健性定义来看OLS estimator，会有哪些弊端。&lt;/p&gt;
&lt;p&gt;混合正态分布，可以理解为一种边缘分布。假设随机变量X服从参数分布F，而F具有参数θ，服从某一种分布G（潜变量分布，未观测到的分布）。所以，可以直观地把X的分布理解为X和θ联合分布的积分，即一种边缘分布。注意，这个概念等价于不同正态分布的叠加，此时结果往往不是正态分布。切勿将其理解为正态随机变量的叠加，其结果为正态分布。&lt;/p&gt;
&lt;p&gt;混合分布对假设检验的直接影响是可能大幅度提高样本均值标准误，并大幅度削弱power。考虑这样的情况，一个心理学家测量心理变量X，但其抽样的总体是被污染的。他假定所有样本都没有精神分裂症，且总体服从N(0,1^2), 但该总体中存在10%的患者，在X上服从N(0, 10^2). 此时的混合分布具有长尾且不服从正态，同时将方差扩大到原先的10.9倍。这使得凡是基于标准差的统计量，比如标准误，受到大幅影响，进而巨幅降低power。更糟糕的是，即使用于检验的两个独立样本都来自钟形曲线，且均值方差相等，其概率密度函数依然可以极大偏离正态分布。这使得基于总体正态分布的检验方法，如小样本时的t分布，在假设检验时面临灾难。&lt;/p&gt;
&lt;p&gt;回到心理学，这个问题有多大可能出现？心理学家argue道，CLT中心极限定理告诉我们，大量独立随机变量均值适当标化后依分布收敛于正态（作为一种illustration，也见高尔顿的钉板和图灵奖得主Judea Pearl的教材）。而且只要样本够大，CLT保证了我们的样本的抽样分布，比如均值分布，渐进正态。&lt;/p&gt;
&lt;p&gt;然而现实中的人类心理并非如此，三个方面。第一，CLT强调的是效应相加，而非相乘。现实世界中更常见的是代表相乘效应的幂律分布，比如马太效应，这可以体现在GPA的分布上（当然指数和对数变换是心理学研究者常常误用的统计方法，详情见各种feature engineering教材）。第二，心理学无法做到随机抽样，都是通过招募，或者是由实验设计决定了目标群体，比如肥胖症患者，各种心理疾病人群，发展心理学研究中的不同年龄组，不同经济地位组，使得正偏态更为常见。第三，我们很大程度上无法确定我们获得的分布是不是混合正态。&lt;/p&gt;
&lt;p&gt;因此，在做最简单的统计检验，比如均值差异时，心理学研究者需要保证其统计方法具有至少两个优势：其一，因变量的集中趋势不应该对概率曲线敏感，比如median敏感性比mean差很多（这里的说法类似传统的qualitative robustness的定义，描述总体统计量的函数，在分布改变时等度连续。请参考Huber2009年和Wilcox2017年的教材）；其二，非正态和混合正态下，统计检验力和标准误不会比正态下有明显变化。&lt;/p&gt;
&lt;p&gt;第二个例子是OLS回归，其后果可以引申到一切类似方法，比如积差相关，逐步、分层回归，路径分析。OLS的问题可以从quantitative robustness的定义看出。Quantitative robustness，一般用有限样本屈服点来界定（finite sample breakdown point）。假设存在混合分布，其中代表异常点的分布在抽样中的比重是c，则异常分布的均值趋于无穷时，让混合分布均值趋于无穷的最小c值，则为屈服点。更简单，更一般的表述是，一种统计量，可以容忍多少个异常值。以此视角，样本均值的屈服点是1，OLS回归的屈服点也是1. 因为任何一个无限大的异常值都可以影响参数估计。OLS的问题是，无论这个异常点来自于因变量（异常值），还是自变量（高杠杆点），都会有巨大影响。&lt;/p&gt;
&lt;p&gt;从一种高屋建瓴的模型角度来理解，则更为清晰。我在给心理学本科生做家教的课件时，曾经写了一般线性模型之间等价关系的证明，即独立t，ANOVA，积差相关，回归，ANCOVA的检验在数学上等价，可惜并没有时间讲。如果从模型的角度，求解样本中心趋势，和求解回归，目标函数是一样的。对求解均值，最小化目标函数是样本的二阶中心矩，然后对其求一节条件，便是均值。而对OLS回归，形式完全不变。所以二者屈服点必为一致。 对二者来说，初始的目标函数都是一个二次函数，这使得异常值以指数对目标函数产生影响。&lt;/p&gt;
&lt;p&gt;回头反思心理学领域的统计应用，为什么基于最小二乘的方法依然大行其道？因为大家从来不做模拟，不知道基于least squares的方法在估计SE和回归系数时有多么不准确。更多的，是因为社科领域重视解释而非预测，所以对总体参数的估计不太在意，只关注关系是否显著。但显著性恰恰是建立在准确的标准误之上的。&lt;/p&gt;
&lt;p&gt;如上所述，对于OLS estimator的改进可能已经暗示得很明显了。如果目标函数是一个二次函数，那么只需要限制异常值对这个目标函数的影响速率，是不是就可以了？这就是最早M-estimator的由来。M估计量首先定义了一个可微函数，描述了集中趋势到其他点的距离，接着，对这个函数微分，令其期望等于0则可求解出该目标函数下的集中趋势。这也暗示着，均值和OLS是M估计量的一种特例。如果采用Huber&amp;rsquo;s \Psi，可以将目标函数改为一个中间是二次函数，两端是一次函数的曲线，这使得样本两端的点被适当降权，减弱了对目标函数的影响。&lt;/p&gt;
&lt;p&gt;当然，如果这么来看，Huber提出的函数并没有提高屈服点，因为即使是线性增加，依然在该异常点趋于无穷时，有无穷大影响。这种早期函数也被后来的新方法取代，比如MM-estimator。&lt;/p&gt;
&lt;p&gt;总结，现代稳健方法的发展似乎呈现如下趋势：首先是基于模拟找出传统方法的弊端，比如估计量的低power，低efficiency，进而寻找概念去描述这种不稳健特性。三个经典的概念是qualitative，quantitative，and infinitesimal robustness。基于这些概念，统计学家开始建立稳健统计理论并寻找稳健估计方法。因为当一种传统方法被稳健概念描述后，可以清晰地知道其问题缘由。比如，发现OLS的低屈服点，那么就去构造高屈服点的estimator；再比如，根据qualitative robustness，要求找到估计量在分布改变时等度连续，或者导数有界。概念之所以重要，是因为他是后续研究的思路，决定了方法如何建立。再之后，就是用计算机进行模拟实验，测试性能。得到稳定的结果后，封装程序，开枝散叶，把统计方法传播到其他应用领域。&lt;/p&gt;
&lt;p&gt;所以，如果一名统计学门外汉（指没有上过专门的统计课，比如笔者这样的人）想要掌握一些基础的现代统计方法，建议按照上述领域发展的进程去学习概念，再用心理学或者其他领域的数据去实践。推荐的作者是Wilcox, Huber, Hampel, Hox等人的教材，tutorial和论文。尤其是Wilcox引用最高的书，可以花1-2天快速扫读一遍。先知道稳健性的数学定义，然后去看集中趋势和散度的估计方法，再到两样本检验，进而到更一般的回归。由于某些统计方法，如M-estimator回归的标准误是渐进方法，因此标准误并非所有情况下都会准确，所以也要搭配区间估计的稳健方法。最后，统计软件推荐R而非python，因为py相关的库还是太少了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://Junsong798.github.io/p/robust-statistics/robust2.png&#34;
	width=&#34;950&#34;
	height=&#34;546&#34;
	srcset=&#34;https://Junsong798.github.io/p/robust-statistics/robust2_hu3f287108adcf3e9070e1f6caf0c2dcdb_13176_480x0_resize_box_3.png 480w, https://Junsong798.github.io/p/robust-statistics/robust2_hu3f287108adcf3e9070e1f6caf0c2dcdb_13176_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;HC3标准误模拟结果&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;417px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
